% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape-listpage.R
\name{get_listpage_data}
\alias{get_listpage_data}
\title{Convenience function to fetch and parse all listpages}
\usage{
get_listpage_data(firstlistpageurl, max_pages = 10,
  delay_listpage = NA, domain = "https://geizhals.at")
}
\arguments{
\item{firstlistpageurl}{Character vector of length 1 containing the
url of a geizhals category page (listing all items of a selected
category).}

\item{max_pages}{Maximal number of pages to be scraped. Default is 10.}

\item{delay_listpage}{Number of seconds to wait between fetching
subsequent list pages.}

\item{domain}{Character vector of length one specifying the domain.
Defaults to \code{"https://geizhals.at"}.}
}
\value{
A tibble (data.frame) containing all information scraped
  from the geizhals pages.
}
\description{
Calls \code{fetch_all_listpages} and then
\code{parse_all_listpages} .
}
\examples{
\dontrun{
url_geizhals <- "https://geizhals.at/?cat=acam35"
get_listpage_data(url_geizhals, max_pages = 2)
}
}
