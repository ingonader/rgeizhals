% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape-detailpage.R
\name{fetch_all_detailpage_html}
\alias{fetch_all_detailpage_html}
\title{Fetch html of detailpage urls}
\usage{
fetch_all_detailpage_html(detailpageurls, max_items = Inf,
  delay_detailpage = NA)
}
\arguments{
\item{detailpageurls}{A character vector containing urls to
sub-pages with detailed product descriptions (as found when following
a link in the listing page).}

\item{max_items}{A numeric (integer) vector of length one, specifying
the maximum number of items to scrape. (Default: \code{Inf}).
If \code{max_items} is smaller than the length of the passed urls
in \code{detailpageurls}, only the first \code{max_items} entries
are fetched.}

\item{delay_detailpage}{Number of seconds to wait after fetching
html of each detailpage (defaults to \code{NA}).}
}
\value{
A list of length two. The first element, \code{url}, contains
  the vector of urls that was passed to the function. The second list
  element, \code{html}, contains another list with one entry per url,
  containing the html.
}
\description{
Retrieve the html code for a vector of detailpage urls, returning
the urls as well as the html code.
}
\examples{
\dontrun{
## first, get data from all listing pages:
url_geizhals <- "https://geizhals.at/?cat=acam35"
listpagehtml_list <- fetch_all_listpages(url_geizhals, max_pages = 2)
dat_listpages <- parse_all_listpages(listpagehtml_list)

## now, get (first three) detailpages:
urls <- dat_listpages$detailpage_url
detailpagehtml_list <- fetch_all_detailpage_html(urls, max_items = 3,
  delay_detailpage = 1)
detailpagehtml_list
}

}
