% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/scrape-listpage.R
\name{read_all_listpages}
\alias{read_all_listpages}
\title{Get html from multiple geizhals category pages}
\usage{
read_all_listpages(firstlistpageurl, max_pages = 10)
}
\arguments{
\item{firstlistpageurl}{Character vector of lenght 1 containting the
url of a geizhals category page (listing all items of a selected
category).}

\item{max_pages}{Maximal number of pages to be scraped. Default is 10.}
}
\value{
A list of xml documents.
}
\description{
Given the url of a geizhals page listing all products
within a specific  category (i.e., not the generic page-wide search from
the search bar, but the page showing all items within a category),
the html code from this and the following pages are returned. Filters
might be applied, only results corresponding to that filter will be
returned.
This list is meant to be processed by the \code{\link{get_all_listpages}}
function.
}
\examples{

url_geizhals <- "https://geizhals.at/?cat=acam35"
listpagehtml_list <- read_all_listpages(url_geizhals, max_pages = 2)
get_all_listpages(listpagehtml_list)

}
\seealso{
\code{\link{get_all_listpages}}
}
